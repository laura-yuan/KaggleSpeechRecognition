{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import system_config as sc\n",
    "\n",
    "system_configuration = sc.get_system_config()\n",
    "sys.path.insert(0, system_configuration['code_tensorlfow'])\n",
    "\n",
    "import input_data\n",
    "import models\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## all the arguments of tensorflow's tutorial.\n",
    "## files management.\n",
    "data_url      = 0\n",
    "data_dir      = system_configuration['data_tensorflow']\n",
    "summaries_dir = os.path.join(system_configuration['train_log_debug'],'retrain_log'  )\n",
    "wanted_words  ='yes,no,up,down,left,right,on,off,stop,go'\n",
    "train_dir     = os.path.join(system_configuration['train_log_debug'], 'speech_commands_train')\n",
    "start_checkpoint=''\n",
    "check_nans=False\n",
    "# help='Whether to check for invalid numbers during processing')\n",
    "\n",
    "## training management\n",
    "background_volume = 0.1\n",
    "background_frequency=0.8\n",
    "silence_percentage=10.0\n",
    "unknown_percentage=10.0\n",
    "testing_percentage=10\n",
    "validation_percentage=10\n",
    "time_shift_ms =100.0\n",
    "how_many_training_steps=['15000,3000']\n",
    "eval_step_interval=400\n",
    "# help='How often to evaluate the training results.')\n",
    "batch_size=100\n",
    "save_step_interval=100\n",
    "\n",
    "## model management\n",
    "model_architecture='conv'\n",
    "learning_rate=['0.001,0.0001']\n",
    "\n",
    "## parameter management\n",
    "\n",
    "## audio processing management.\n",
    "sample_rate = 16000\n",
    "clip_duration_ms = 1000\n",
    "window_size_ms = 30.0\n",
    "# help='How long each spectrogram timeslice is',)\n",
    "window_stride_ms = 10.0\n",
    "# help='How long each spectrogram timeslice is',)\n",
    "dct_coefficient_count = 40\n",
    "\n",
    "## our parameter\n",
    "# clean up the data a little bit\n",
    "pct_thresh = [5, 99]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug model.\n",
    "model_settings = models.prepare_model_settings(\n",
    "  len(input_data.prepare_words_list(wanted_words.split(','))),\n",
    "  sample_rate, clip_duration_ms, window_size_ms,\n",
    "  window_stride_ms, dct_coefficient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dct_coefficient_count': 40,\n",
       " 'desired_samples': 16000,\n",
       " 'fingerprint_size': 3920,\n",
       " 'label_count': 12,\n",
       " 'sample_rate': 16000,\n",
       " 'spectrogram_length': 98,\n",
       " 'window_size_samples': 480,\n",
       " 'window_stride_samples': 160}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_size = model_settings['fingerprint_size']\n",
    "fingerprint_input = tf.placeholder(\n",
    "  tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "if is_training:\n",
    "    dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')\n",
    "\n",
    "input_frequency_size = model_settings['dct_coefficient_count']\n",
    "input_time_size = model_settings['spectrogram_length']\n",
    "fingerprint_4d = tf.reshape(fingerprint_input,\n",
    "                          [-1, input_time_size, input_frequency_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"W:0\", shape=(28, 8, 1, 64), dtype=float32_ref) must be from the same graph as Tensor(\"Reshape_1:0\", shape=(?, 98, 40, 1), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ae81000d33c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model_conv2_with_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfingerprint_4d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-7b3fb8eb80b5>\u001b[0m in \u001b[0;36mcreate_model_conv2_with_name_scope\u001b[1;34m(fingerprint_input, model_settings, is_training)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m## first layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'layer_1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfingerprint_4d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F_strides1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-7b3fb8eb80b5>\u001b[0m in \u001b[0;36mconv_layer\u001b[1;34m(X, f, strides, layer_name, act, use_cudnn_on_gpu)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'VALID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Z'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Activation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kaggle_speechrec\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kaggle_speechrec\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kaggle_speechrec\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   5040\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5041\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5042\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5043\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5044\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kaggle_speechrec\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   4976\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4977\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[1;32m-> 4978\u001b[1;33m                                                                 original_item))\n\u001b[0m\u001b[0;32m   4979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"W:0\", shape=(28, 8, 1, 64), dtype=float32_ref) must be from the same graph as Tensor(\"Reshape_1:0\", shape=(?, 98, 40, 1), dtype=float32)."
     ]
    }
   ],
   "source": [
    "is_training = True\n",
    "tf.reset_default_graph()\n",
    "a = create_model_conv2_with_name_scope(fingerprint_4d, model_settings, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, namescope_this):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "       Tensor can be the activity of hidden layer.Monitor the saturation.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(namescope_this):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y, namescope_this):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_H0, n_W0, n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape = (None, n_y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "    \n",
    "    return parameters\n",
    "def conv_layer(X, f, strides, layer_name, act=tf.nn.relu, use_cudnn_on_gpu=False):\n",
    "    \"\"\"\n",
    "    Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window [20, 8, 1, 64]\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    Y -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(layer_name):\n",
    "        print(layer_name)\n",
    "        W = tf.get_variable('W', f, initializer= tf.contrib.layers.xavier_initializer())\n",
    "        B = tf.get_variable('bias', f[3], initializer= tf.zeros_initializer())\n",
    "        Z = tf.nn.conv2d(X, W, strides = strides, padding = 'VALID', use_cudnn_on_gpu = use_cudnn_on_gpu, name = 'Z') + B\n",
    "        A = act(Z, name = 'Activation')\n",
    "        \n",
    "        variable_summaries(W, 'W')\n",
    "        variable_summaries(B, 'B')\n",
    "        variable_summaries(Z, 'WX+B')\n",
    "        variable_summaries(A, 'activation')\n",
    "        \n",
    "    return A\n",
    "    \n",
    "def create_model_conv2_with_name_scope(fingerprint_input, model_settings, is_training):\n",
    "#         parameters = model_settings['parameter']\n",
    "\n",
    "    parameters = {}\n",
    "    parameters['W1'] = [28, 8, 1, 64]\n",
    "    parameters['F_strides1'] = [1,1,1,1]\n",
    "    parameters['M1'] = [1, 2, 2, 1]\n",
    "    parameters['M_strides1'] = [1, 2, 2, 1]\n",
    "\n",
    "    \n",
    "    parameters['W2'] = [10, 4, 64, 64]\n",
    "    parameters['F_strides2'] = [1,1,1,1]\n",
    "    parameters['M2'] = [1, 2, 2, 1]\n",
    "    parameters['M_strides2'] = [1, 2, 2, 1]\n",
    "\n",
    "    parameters['W3'] = [5, 2, 64, 128]\n",
    "    parameters['F_strides3'] = [1,1,1,1]\n",
    "    parameters['M3'] = [1, 2, 2, 1]\n",
    "    parameters['M_strides3'] = [1, 2, 2, 1]\n",
    "\n",
    "    parameters['W3'] = [5, 2, 128, 128]\n",
    "    parameters['F_strides3'] = [1,1,1,1]\n",
    "    parameters['M3'] = [1, 2, 2, 1]\n",
    "    parameters['M_strides3'] = [1, 2, 2, 1]\n",
    "\n",
    "    parameters['W4'] = [5, 2, 128, 128]\n",
    "    parameters['F_strides4'] = [1,1,1,1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if is_training:\n",
    "        dropout_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    # reshape input\n",
    "    input_frequency_size = model_settings['dct_coefficient_count']\n",
    "    input_time_size = model_settings['spectrogram_length']\n",
    "    fingerprint_4d = tf.reshape(fingerprint_input,\n",
    "                              [-1, input_time_size, input_frequency_size, 1])\n",
    "    \n",
    "    ## first layer.\n",
    "    layer_name = 'layer_1'\n",
    "    hidden1 = conv_layer(fingerprint_4d, parameters['W1'], parameters['F_strides1'], layer_name, act=tf.nn.relu, use_cudnn_on_gpu=False)\n",
    "    with tf.name_scope(layer_name):\n",
    "        if is_training:\n",
    "            hidden1_dropout = tf.nn.dropout(hidden1, dropout_prob)\n",
    "        else:\n",
    "            hidden1_dropout = hidden1\n",
    "    \n",
    "        maxpool1= tf.nn.max_pool(hidden1_dropout,  ksize = parameters['M1'], strides = parameters['M_strides1'], padding = 'SAME')\n",
    "\n",
    "    \n",
    "    # second layer\n",
    "    layer_name = 'layer_2'\n",
    "    hidden2 = conv_layer(maxpool1, parameters['W2'], parameters['F_strides2'], layer_name, act=tf.nn.relu, use_cudnn_on_gpu=False)\n",
    "    with tf.name_scope(layer_name):\n",
    "        if is_training:\n",
    "            hidden2_dropout = tf.nn.dropout(hidden2, dropout_prob)\n",
    "        else:\n",
    "            hidden2_dropout = hidden2\n",
    "    \n",
    "        maxpool2= tf.nn.max_pool(hidden2_dropout,  ksize = parameters['M2'], strides = parameters['M_strides2'], padding = 'SAME')\n",
    "\n",
    "   ## third layer.\n",
    "    layer_name = 'layer_3'\n",
    "    hidden3 = conv_layer(maxpool2, parameters['W3'], parameters['F_strides3'], layer_name, act=tf.nn.relu, use_cudnn_on_gpu=False)\n",
    "    with tf.name_scope(layer_name):\n",
    "        if is_training:\n",
    "            hidden3_dropout = tf.nn.dropout(hidden3, dropout_prob)\n",
    "        else:\n",
    "            hidden3_dropout = hidden3\n",
    "        \n",
    "        maxpool3= tf.nn.max_pool(hidden3_dropout,  ksize = parameters['M3'], strides = parameters['M_strides3'], padding = 'SAME')\n",
    "      \n",
    "    layer_name = 'layer_4'\n",
    "    hidden4 = conv_layer(hidden3_dropout, parameters['W4'], parameters['F_strides4'], layer_name, act=tf.nn.relu, use_cudnn_on_gpu=False)\n",
    "    with tf.name_scope(layer_name):\n",
    "        if is_training:\n",
    "            hidden4_dropout = tf.nn.dropout(hidden4, dropout_prob)\n",
    "        else:\n",
    "            hidden4_dropout = hidden4\n",
    "    \n",
    "    ## hidden4 is used for fully connected layer.\n",
    "    layer_name = 'fully_connected'\n",
    "    with tf.name_scope( layer_name):\n",
    "        label_count = model_settings['label_count']\n",
    "        last_layer = tf.contrib.layers.flatten(hidden4_dropout)\n",
    "        final_fc = tf.contrib.layers.fully_connected(last_layer, label_count, activation_fn=None)\n",
    "\n",
    "    if is_training:\n",
    "        return final_fc, dropout_prob\n",
    "    else:\n",
    "        return final_fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_speechrec]",
   "language": "python",
   "name": "conda-env-kaggle_speechrec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
